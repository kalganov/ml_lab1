{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling-Up Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are familiar with sequence to sequence models let’s discuss  how to scale them to real world problems. In the previous example we used a very small vocabulary (4 symbols $“a,b,c,d”$)  but when dealing with tasks such as machine translation our vocabulary can contain thousands of unique words, that means that the last layer of our network must be the dimension as the size of the vocabulary and $softmax$ must be applied on an extremely long vector. When training a network we cannot afford such a costly operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why hierarchical softmax was invented, it can increase softmax computation time by up to $log(n)$ without compromising too much of the network reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function, or normalized exponential is used to transform a $n$ dimensional vector into a probability over $n$ classes, formally it is defined as: $P(class=i | x) = \\dfrac{e^{x_i}}{\\sum_{j=1}^ne^{x_j}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy code for SoftMax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the softmax we need to $O(n)$ time. Let's see how can we reduce it to $O(log(n))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hierarchical Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens to the computation complexity if we divide our vocabulary into to 2 equal non-overlapping groups, and change the classification process to first selecting the group $P(group=i|x)=softmax(x*W_{groupselect}+b_{groupselect})$ and then selecting the word from the group $P(word=w|x) = P(group=i|x)P(word=w|x, group=i)$. Before the computation required us to was $|x||n|+|n|$ operations. After the splitting selecting the group takes $2|x|+2$ operations and selecting the correct item from the group takes $\\dfrac{n}{2}|x|+\\dfrac{n}{2}$ operations. We reduced the total operations to $(2+\\dfrac{n}{2})|x|+2+\\dfrac{n}{2}$, for large vocabularies this could mean great reduction in computation time. We can segment our vocabulary however we like and achieve up to $log(n)$ speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the hierarchical softmax function first  it arranges the output vocabulary in an hierarchical tree (we will discuss later how this tree can be constructed). Once we constructed the tree we can use softmax to select each branch of the tree. For example, given the following hierarchy and the value of the last hidden layer is $V$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/HierSoftMax.jpg\" width=\"25%\" height=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of the network to predict \"D\" is (the probability of choosing the 2nd branch in $B_1$)*(the probability of choosing the 1st branch on $B_3$). More formally:  $P(class=D | V) = softmax(V \\times W_{B_1})_1*softmax(V \\times W_{B_3})_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what is hierarchical softmax we can start implementing it. We will create an hier_softmax that will receive an output hierarchy and will be able to calculate of the probability of an output given $V$ and to generate to most likely output given a vector $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define some auxiliary functions to handle trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from copy import copy\n",
    "\n",
    "class TreeTools:\n",
    "    def __init__(self):\n",
    "        #memoization for _count_nodes functions\n",
    "        self._count_nodes_dict = {}\n",
    "                \n",
    "    def _get_subtrees(self, tree):\n",
    "        yield tree\n",
    "        for subtree in tree:\n",
    "            if type(subtree) == list:\n",
    "                for x in self._get_subtrees(subtree):\n",
    "                    yield x\n",
    "\n",
    "    # Returns pairs of paths and leafves of a tree\n",
    "    def _get_leaves_paths(self, tree):\n",
    "        for i, subtree in enumerate(tree):\n",
    "            if type(subtree) == list:\n",
    "                for path, value in self._get_leaves_paths(subtree):\n",
    "                    yield [i] + path, value\n",
    "            else:\n",
    "                yield [i], subtree\n",
    "    \n",
    "    # Returns the number of nodes in a tree (not including root)\n",
    "    def _count_nodes(self, tree):\n",
    "        if id(self._count_nodes_dict) in self._count_nodes_dict:\n",
    "            return self._count_nodes_dict[id(self._count_nodes_dict)]\n",
    "        size = 0\n",
    "        for node in tree:\n",
    "            if type(node) == list:\n",
    "                size += 1 + self._count_nodes(node)\n",
    "        self._count_nodes_dict[id(self._count_nodes_dict)] = size\n",
    "        return size\n",
    "\n",
    "\n",
    "    # Returns all the nodes in a path\n",
    "    def _get_nodes(self, tree, path):\n",
    "        next_node = 0\n",
    "        nodes = []\n",
    "        for decision in path:\n",
    "            nodes.append(next_node)\n",
    "            next_node += 1 + self._count_nodes(tree[:decision])\n",
    "            tree = tree[decision]\n",
    "        return nodes\n",
    "\n",
    "\n",
    "# turns a list to a binary tree\n",
    "def random_binary_full_tree(outputs):\n",
    "    outputs = copy(outputs)\n",
    "    shuffle(outputs)\n",
    "\n",
    "    while len(outputs) > 2:\n",
    "        temp_outputs = []\n",
    "        for i in range(0, len(outputs), 2):\n",
    "            if len(outputs) - (i+1) > 0:\n",
    "                temp_outputs.append([outputs[i], outputs[i+1]])\n",
    "            else:\n",
    "                temp_outputs.append(outputs[i])\n",
    "        outputs = temp_outputs\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tree: [[[[6, 2], [7, 4]], [[9, 0], [8, 5]]], [1, 3]]\n",
      "All subtrees:\n",
      "\t[[[[6, 2], [7, 4]], [[9, 0], [8, 5]]], [1, 3]]\n",
      "\t[[[6, 2], [7, 4]], [[9, 0], [8, 5]]]\n",
      "\t[[6, 2], [7, 4]]\n",
      "\t[6, 2]\n",
      "\t[7, 4]\n",
      "\t[[9, 0], [8, 5]]\n",
      "\t[9, 0]\n",
      "\t[8, 5]\n",
      "\t[1, 3]\n",
      "All paths and leaves:\n",
      "\t([0, 0, 0, 0], 6)\n",
      "\t([0, 0, 0, 1], 2)\n",
      "\t([0, 0, 1, 0], 7)\n",
      "\t([0, 0, 1, 1], 4)\n",
      "\t([0, 1, 0, 0], 9)\n",
      "\t([0, 1, 0, 1], 0)\n",
      "\t([0, 1, 1, 0], 8)\n",
      "\t([0, 1, 1, 1], 5)\n",
      "\t([1, 0], 1)\n",
      "\t([1, 1], 3)\n",
      "Number of nodes in the tree: 14\n",
      "all nodes in path [0, 0, 0, 0]:\n",
      "\t0\n",
      "\t15\n",
      "\t30\n",
      "\t45\n"
     ]
    }
   ],
   "source": [
    "tree = random_binary_full_tree(range(10))\n",
    "print 'Our tree:',tree\n",
    "\n",
    "tree_tools = TreeTools()\n",
    "\n",
    "print 'All subtrees:'\n",
    "for subtree in tree_tools._get_subtrees(tree):\n",
    "    print '\\t',subtree\n",
    "\n",
    "print 'All paths and leaves:'\n",
    "for subtree in tree_tools._get_leaves_paths(tree):\n",
    "    print '\\t',subtree\n",
    "    \n",
    "print 'Number of nodes in the tree:',tree_tools._count_nodes(tree)\n",
    "\n",
    "print 'all nodes in path [0, 0, 0, 0]:'\n",
    "for nodes in tree_tools._get_nodes(tree, [0, 0, 0, 0]):\n",
    "    print '\\t',nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to write the hierarchical softmax class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycnn as pc\n",
    "\n",
    "class hier_softmax:\n",
    "    def __init__(self, tree, contex_size, model):\n",
    "        self._tree_tools = TreeTools()\n",
    "        \n",
    "        #create a weight matrix and bias vector for each node in the tree\n",
    "        for i, subtree in enumerate(self._tree_tools._get_subtrees(tree)):\n",
    "            model.add_parameters(\"softmax_node_\"+str(i)+\"_w\", (len(subtree), contex_size))\n",
    "            model.add_parameters(\"softmax_node_\" + str(i) + \"_b\", len(subtree))\n",
    "        \n",
    "        #create a dictionary from each value to its path\n",
    "        value_to_path_and_nodes_dict = {}\n",
    "        for path, value in self._tree_tools._get_leaves_paths(tree):\n",
    "            nodes = self._tree_tools._get_nodes(tree, path)\n",
    "            value_to_path_and_nodes_dict[data.char2int[value]] = path, nodes\n",
    "        self.value_to_path_and_nodes_dict = value_to_path_and_nodes_dict\n",
    "        self.model = model\n",
    "        self.tree = tree\n",
    "    \n",
    "    #get the loss on a given value (for training)\n",
    "    def get_loss(self, context, value):\n",
    "        loss = []\n",
    "        path, nodes = self.value_to_path_and_nodes_dict[value]\n",
    "        for p, n in zip(path, nodes):\n",
    "            w = pc.parameter(self.model[\"softmax_node_\"+str(n)+\"_w\"])\n",
    "            b = pc.parameter(self.model[\"softmax_node_\" + str(n) + \"_b\"])\n",
    "            probs = pc.softmax(w*context+b)\n",
    "            loss.append(-pc.log(pc.pick(probs, p)))\n",
    "        return pc.esum(loss)\n",
    "\n",
    "    #get the most likely\n",
    "    def generate(self, context):\n",
    "        best_value = None\n",
    "        best_loss = float(100000)\n",
    "        for value in self.value_to_path_and_nodes_dict:\n",
    "            loss = self.get_loss(context, value)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_value = value\n",
    "        return best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the performance improvement we can get from the hier_softmax. Again, we will learn the reverse function, but this time on a much bigger vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('584 949 242 188', '188 242 949 584')\n"
     ]
    }
   ],
   "source": [
    "from random import choice, randrange\n",
    "import data\n",
    "\n",
    "data.set_vocab_size(1000)\n",
    "\n",
    "print data.sample_model(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "MAX_STRING_LEN = 5\n",
    "\n",
    "train_set = [data.sample_model(1, MAX_STRING_LEN) for _ in xrange(3000)]\n",
    "val_set = [data.sample_model(1, MAX_STRING_LEN) for _ in xrange(50)]\n",
    "\n",
    "def train(network, train_set, val_set, epochs = 20):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "        return sum(loss)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    trainer = pc.SimpleSGDTrainer(network.model)\n",
    "    start = datetime.now()\n",
    "    for i, training_example in enumerate(train_set):\n",
    "        input_string, output_string = training_example\n",
    "        \n",
    "        loss = network.get_loss(input_string, output_string)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print datetime.now()-start\n",
    "        \n",
    "\n",
    "    print 'loss on validation set:', get_val_set_loss(network, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a large vocab data we can measure the training time of the attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import AttentionNetwork\n",
    "\n",
    "ENC_RNN_NUM_OF_LAYERS = 1\n",
    "DEC_RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 200\n",
    "ENC_STATE_SIZE = 210\n",
    "DEC_STATE_SIZE = 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "att = AttentionNetwork(ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:08:47.077443\n",
      "loss on validation set: 5.34234179708\n"
     ]
    }
   ],
   "source": [
    "train(att, train_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add hierarchical softmax to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_tree = random_binary_full_tree(data.characters)\n",
    "\n",
    "RNN_BUILDER = pc.LSTMBuilder\n",
    "class AttentionNetworkWithHierSoftmax(AttentionNetwork):\n",
    "    def __init__(self, enc_layers, dec_layers, embeddings_size, enc_state_size, dec_state_size, tree):\n",
    "        self.model = pc.Model()\n",
    "\n",
    "        # the embedding paramaters\n",
    "        self.model.add_lookup_parameters(\"lookup\", (data.VOCAB_SIZE, embeddings_size))\n",
    "\n",
    "        # the rnns\n",
    "        self.ENC_RNN = RNN_BUILDER(enc_layers, embeddings_size, enc_state_size, self.model)\n",
    "        self.DEC_RNN = RNN_BUILDER(dec_layers, enc_state_size, dec_state_size, self.model)\n",
    "        \n",
    "        # attention weights\n",
    "        self.model.add_parameters(\"attention_w1\", (enc_state_size, enc_state_size))\n",
    "        self.model.add_parameters(\"attention_w2\", (enc_state_size, dec_state_size))\n",
    "        self.model.add_parameters(\"attention_v\", (1, enc_state_size))\n",
    "\n",
    "        self.enc_state_size = enc_state_size\n",
    "        \n",
    "        self.hier_softmax = hier_softmax(tree, dec_state_size, self.model)\n",
    "    \n",
    "    def _get_probs(self, rnn_output, output_char):\n",
    "        return self.hier_softmax.get_loss(rnn_output, output_char)\n",
    "    \n",
    "    def _predict(self, rnn_output):\n",
    "        return self.self.hier_softmax.generate(rnn_output)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "att = AttentionNetworkWithHierSoftmax(\n",
    "    ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE, output_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:07:28.904483\n",
      "loss on validation set: 0.0389896153592\n"
     ]
    }
   ],
   "source": [
    "train(att, train_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the hierarchical softmax shaved almost 12.5% off our training time. On real world data a vocabulary of 1,000 words is considered tiny so the gain should be considerably higher. Other difference from real word data is that the training examples will not be uniformly distributed and external information (such as wordnet) can further improve the hier softmax performance (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8829&rep=rep1&type=pdf#page=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.036986\n",
      "loss on validation set: 20.4717674255\n",
      "0:00:00.184931\n",
      "loss on validation set: 22.8816108704\n"
     ]
    }
   ],
   "source": [
    "data.set_vocab_size(100000)\n",
    "\n",
    "train_set = [data.sample_model(1, MAX_STRING_LEN) for _ in xrange(1)]\n",
    "val_set = [data.sample_model(1, MAX_STRING_LEN) for _ in xrange(1)]\n",
    "\n",
    "output_tree = random_binary_full_tree(data.characters)\n",
    "\n",
    "\n",
    "ENC_RNN_NUM_OF_LAYERS = 1\n",
    "DEC_RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 10\n",
    "ENC_STATE_SIZE = 10\n",
    "DEC_STATE_SIZE = 100\n",
    "\n",
    "\n",
    "att = AttentionNetworkWithHierSoftmax(\n",
    "    ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE, output_tree)\n",
    "\n",
    "train(att, train_set, val_set, 1)\n",
    "\n",
    "att = AttentionNetwork(\n",
    "    ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE)\n",
    "\n",
    "train(att, train_set, val_set, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this extreme example we achieved 5x speedup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More methods to deal with large vocabulary https://www.tensorflow.org/extras/candidate_sampling.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About me: https://www.cs.bgu.ac.il/~talbau/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
